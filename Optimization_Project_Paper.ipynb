{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 选取每个industry top3的股票来建立portfolio"
      ],
      "metadata": {
        "id": "cNqrQIpINvKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FMEj910Na0k",
        "outputId": "99a77ea5-5b26-400e-802a-6ea11ed61813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  33 of 33 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Daily returns calculated and saved.\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Top 3 stocks from each GICS sector\n",
        "tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"NVDA\",  # Technology\n",
        "    \"JNJ\", \"PFE\", \"UNH\",     # Healthcare\n",
        "    \"JPM\", \"BAC\", \"WFC\",     # Financials\n",
        "    \"XOM\", \"CVX\", \"COP\",     # Energy\n",
        "    \"PG\", \"KO\", \"PEP\",       # Consumer Staples\n",
        "    \"HD\", \"LOW\", \"TGT\",      # Consumer Discretionary\n",
        "    \"NEE\", \"DUK\", \"SO\",      # Utilities\n",
        "    \"GOOGL\", \"META\", \"DIS\",  # Communication Services\n",
        "    \"UNP\", \"HON\", \"RTX\",     # Industrials\n",
        "    \"SHW\", \"LIN\", \"FCX\",     # Materials\n",
        "    \"AMT\", \"PLD\", \"EQIX\"     # Real Estate\n",
        "]\n",
        "\n",
        "# Download full multi-indexed data\n",
        "data = yf.download(tickers, start=\"2020-01-01\", end=\"2024-12-31\", group_by='ticker', auto_adjust=True)\n",
        "\n",
        "# Extract \"Adj Close\" prices correctly for all tickers\n",
        "adj_close = pd.concat([data[ticker]['Close'] for ticker in tickers], axis=1)\n",
        "adj_close.columns = tickers\n",
        "\n",
        "# Calculate daily returns\n",
        "returns = adj_close.pct_change().dropna()\n",
        "\n",
        "# Save or display\n",
        "returns.to_csv(\"sector_portfolio_returns.csv\")\n",
        "print(\"✅ Daily returns calculated and saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 现在首先计算等权重投资组合的年年回报率和年波动率（hold不变，作为benchmark），然后使用传统的mean variance法，每天和每周、每月调整投资组合，并计算该投资组合的年回报率、年波动率。用作benchmark"
      ],
      "metadata": {
        "id": "BOMjwP92O9WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_stocks = returns.shape[1]\n",
        "equal_weights = np.ones(n_stocks) / n_stocks\n",
        "equal_portfolio_returns = returns.dot(equal_weights)\n",
        "\n",
        "annual_return = (1 + equal_portfolio_returns.mean()) ** 252 - 1\n",
        "annual_volatility = equal_portfolio_returns.std() * np.sqrt(252)\n",
        "risk_free_rate = 0.02\n",
        "sharpe_ratio = (annual_return - risk_free_rate) / annual_volatility\n",
        "\n",
        "print(f\"Equal-Weighted Portfolio\")\n",
        "print(f\"Annual Return: {annual_return:.4f}\")\n",
        "print(f\"Annual Volatility: {annual_volatility:.4f}\")\n",
        "print(f\"Sharpe Ratio (Rf=2%): {sharpe_ratio:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmhXix56OU04",
        "outputId": "8a40e8f1-ee3a-4ad8-c026-1b48a210b1a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equal-Weighted Portfolio\n",
            "Annual Return: 0.1841\n",
            "Annual Volatility: 0.2134\n",
            "Sharpe Ratio (Rf=2%): 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "\n",
        "# === Load return data ===\n",
        "returns = pd.read_csv(\"sector_portfolio_returns.csv\", index_col=0, parse_dates=True)\n",
        "returns = returns.dropna(axis=1)\n",
        "\n",
        "# === Define Parameters and Data class ===\n",
        "class Parameters:\n",
        "    def __init__(self, n_assets):\n",
        "        self.w_min = np.zeros(n_assets)\n",
        "        self.w_max = np.ones(n_assets)\n",
        "        self.c_min = -0.1\n",
        "        self.c_max = 0.1\n",
        "        self.L_tar = 1.0\n",
        "        self.T_tar = 0.2\n",
        "        self.z_min = -0.2 * np.ones(n_assets)\n",
        "        self.z_max = 0.2 * np.ones(n_assets)\n",
        "        self.gamma_hold = 0.01\n",
        "        self.gamma_trade = 0.01\n",
        "        self.risk_target = 0.04\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, mean, cov, w_prev, kappa_short, kappa_borrow, kappa_spread, kappa_impact):\n",
        "        self.mean = mean\n",
        "        self.cov = cov\n",
        "        self.w_prev = w_prev\n",
        "        self.kappa_short = kappa_short\n",
        "        self.kappa_borrow = kappa_borrow\n",
        "        self.kappa_spread = kappa_spread\n",
        "        self.kappa_impact = kappa_impact\n",
        "\n",
        "# === DCP Failure Counter ===\n",
        "dcp_fail_count = 0\n",
        "\n",
        "# === Markowitz Optimizer ===\n",
        "def markowitz(data: Data, param: Parameters, verbose=False):\n",
        "    global dcp_fail_count\n",
        "    n_assets = param.w_min.shape[0]\n",
        "    w, c = cp.Variable(n_assets), cp.Variable()\n",
        "    z = w - data.w_prev\n",
        "    T = cp.norm1(z) / 2\n",
        "    L = cp.norm1(w)\n",
        "\n",
        "    risk = cp.quad_form(w, data.cov)\n",
        "    ret = w.T @ data.mean\n",
        "\n",
        "    holding_cost = data.kappa_short @ cp.pos(-w) + data.kappa_borrow * cp.pos(-c)\n",
        "    trading_cost = data.kappa_spread @ cp.abs(z) + data.kappa_impact @ cp.power(cp.abs(z), 3 / 2)\n",
        "\n",
        "    objective = ret - param.gamma_hold * holding_cost - param.gamma_trade * trading_cost\n",
        "\n",
        "    constraints = [\n",
        "        cp.sum(w) + c == 1,\n",
        "        param.w_min <= w,\n",
        "        w <= param.w_max,\n",
        "        L <= param.L_tar,\n",
        "        param.c_min <= c,\n",
        "        c <= param.c_max,\n",
        "        param.z_min <= z,\n",
        "        z <= param.z_max,\n",
        "        T <= param.T_tar,\n",
        "        risk <= param.risk_target\n",
        "    ]\n",
        "\n",
        "    problem = cp.Problem(cp.Maximize(objective), constraints)\n",
        "\n",
        "    if not problem.is_dcp():\n",
        "        dcp_fail_count += 1\n",
        "        if verbose:\n",
        "            print(\"DCP check failed.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        problem.solve()\n",
        "        return w.value\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Solver error: {e}\")\n",
        "        return None\n",
        "\n",
        "# === Rebalancing Simulation ===\n",
        "def simulate_markowitz_rebalancing(returns, rebalance_freq='M', lookback=60):\n",
        "    returns = returns.dropna(axis=1)\n",
        "    dates = returns.index\n",
        "    n_assets = returns.shape[1]\n",
        "\n",
        "    w_prev = np.ones(n_assets) / n_assets\n",
        "    portfolio_returns = []\n",
        "\n",
        "    kappa_short = 0.001 * np.ones(n_assets)\n",
        "    kappa_borrow = 0.001\n",
        "    kappa_spread = 0.005 * np.ones(n_assets)\n",
        "    kappa_impact = 0.01 * np.ones(n_assets)\n",
        "    param = Parameters(n_assets)\n",
        "\n",
        "    for i in range(lookback, len(returns)):\n",
        "        date = dates[i]\n",
        "        rebalance = (\n",
        "            rebalance_freq == 'D' or\n",
        "            (rebalance_freq == 'W' and date.weekday() == 0) or\n",
        "            (rebalance_freq == 'M' and date.day == 1)\n",
        "        )\n",
        "\n",
        "        if rebalance:\n",
        "            window = returns.iloc[i - lookback:i]\n",
        "            mu = window.mean().values * 252\n",
        "            cov = window.cov().values * 252\n",
        "            data = Data(mu, cov, w_prev, kappa_short, kappa_borrow, kappa_spread, kappa_impact)\n",
        "            w_opt = markowitz(data, param)\n",
        "            if w_opt is not None:\n",
        "                w_prev = w_opt\n",
        "\n",
        "        daily_return = returns.iloc[i].values @ w_prev\n",
        "        portfolio_returns.append(daily_return)\n",
        "\n",
        "    return pd.Series(portfolio_returns, index=returns.index[lookback:])\n",
        "\n",
        "# === Run simulations ===\n",
        "mvo_daily = simulate_markowitz_rebalancing(returns, 'D')\n",
        "mvo_weekly = simulate_markowitz_rebalancing(returns, 'W')\n",
        "mvo_monthly = simulate_markowitz_rebalancing(returns, 'M')\n",
        "\n",
        "# === Calculate annual metrics and Sharpe ratio ===\n",
        "def metrics_with_sharpe(r):\n",
        "    ann_return = (1 + r.mean()) ** 252 - 1\n",
        "    ann_vol = r.std() * np.sqrt(252)\n",
        "    sharpe = ann_return / ann_vol if ann_vol != 0 else np.nan\n",
        "    return ann_return, ann_vol, sharpe\n",
        "\n",
        "metrics = pd.DataFrame({\n",
        "    \"Strategy\": [\"MVO Daily\", \"MVO Weekly\", \"MVO Monthly\"],\n",
        "    \"Annual Return\": [metrics_with_sharpe(mvo_daily)[0],\n",
        "                      metrics_with_sharpe(mvo_weekly)[0],\n",
        "                      metrics_with_sharpe(mvo_monthly)[0]],\n",
        "    \"Annual Volatility\": [metrics_with_sharpe(mvo_daily)[1],\n",
        "                          metrics_with_sharpe(mvo_weekly)[1],\n",
        "                          metrics_with_sharpe(mvo_monthly)[1]],\n",
        "    \"Sharpe Ratio\": [metrics_with_sharpe(mvo_daily)[2],\n",
        "                     metrics_with_sharpe(mvo_weekly)[2],\n",
        "                     metrics_with_sharpe(mvo_monthly)[2]]\n",
        "})\n",
        "\n",
        "print(metrics)\n",
        "print(f\"Total DCP check failed: {dcp_fail_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViXU3-dbaLh0",
        "outputId": "e0d24f64-1974-4a5b-cf0f-4fea1802739a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Strategy  Annual Return  Annual Volatility  Sharpe Ratio\n",
            "0    MVO Daily       0.236335           0.218295      1.082641\n",
            "1   MVO Weekly       0.185007           0.218523      0.846625\n",
            "2  MVO Monthly       0.402794           0.225048      1.789812\n",
            "Total DCP check failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 用新的风险控制代替variance，这里我换了VIX 用industry sentimental index试试，其他的还有CVAR 和 HMM"
      ],
      "metadata": {
        "id": "aVLdi0Esda-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "\n",
        "# === Step 1: ETF 对应行业 ===\n",
        "sector_etfs = {\n",
        "    \"Technology\": \"XLK\",\n",
        "    \"Healthcare\": \"XLV\",\n",
        "    \"Financials\": \"XLF\",\n",
        "    \"Energy\": \"XLE\",\n",
        "    \"Consumer Staples\": \"XLP\",\n",
        "    \"Consumer Discretionary\": \"XLY\",\n",
        "    \"Utilities\": \"XLU\",\n",
        "    \"Communication Services\": \"XLC\",\n",
        "    \"Industrials\": \"XLI\",\n",
        "    \"Materials\": \"XLB\",\n",
        "    \"Real Estate\": \"XLRE\"\n",
        "}\n",
        "\n",
        "# === Step 2: 股票 -> 行业 映射 ===\n",
        "stock_sector_map = {\n",
        "    \"AAPL\": \"Technology\", \"MSFT\": \"Technology\", \"NVDA\": \"Technology\",\n",
        "    \"JNJ\": \"Healthcare\", \"PFE\": \"Healthcare\", \"UNH\": \"Healthcare\",\n",
        "    \"JPM\": \"Financials\", \"BAC\": \"Financials\", \"WFC\": \"Financials\",\n",
        "    \"XOM\": \"Energy\", \"CVX\": \"Energy\", \"COP\": \"Energy\",\n",
        "    \"PG\": \"Consumer Staples\", \"KO\": \"Consumer Staples\", \"PEP\": \"Consumer Staples\",\n",
        "    \"HD\": \"Consumer Discretionary\", \"LOW\": \"Consumer Discretionary\", \"TGT\": \"Consumer Discretionary\",\n",
        "    \"NEE\": \"Utilities\", \"DUK\": \"Utilities\", \"SO\": \"Utilities\",\n",
        "    \"GOOGL\": \"Communication Services\", \"META\": \"Communication Services\", \"DIS\": \"Communication Services\",\n",
        "    \"UNP\": \"Industrials\", \"HON\": \"Industrials\", \"RTX\": \"Industrials\",\n",
        "    \"SHW\": \"Materials\", \"LIN\": \"Materials\", \"FCX\": \"Materials\",\n",
        "    \"AMT\": \"Real Estate\", \"PLD\": \"Real Estate\", \"EQIX\": \"Real Estate\"\n",
        "}\n",
        "\n",
        "# === Step 3: 下载 ETF 数据 ===\n",
        "etf_tickers = list(sector_etfs.values())\n",
        "etf_data = yf.download(etf_tickers, start=\"2020-01-01\", end=\"2024-12-31\", auto_adjust=True)\n",
        "etf_prices = etf_data['Close']\n",
        "etf_returns = etf_prices.pct_change().dropna()\n",
        "\n",
        "# === Step 4: 滚动年化波动率 (21日窗口)\n",
        "vol_window = 21\n",
        "rolling_vol = etf_returns.rolling(window=vol_window).std() * np.sqrt(252)\n",
        "\n",
        "# === Step 5: 计算 rolling z-score （每日）\n",
        "zscore_daily = (rolling_vol - rolling_vol.mean()) / rolling_vol.std()\n",
        "zscore_daily = zscore_daily.dropna()\n",
        "\n",
        "# === Step 6: 提取每周（周一）、每月（1号）z-score\n",
        "zscore_weekly = zscore_daily[zscore_daily.index.weekday == 0]\n",
        "zscore_monthly = zscore_daily[zscore_daily.index.day == 1]\n",
        "\n",
        "# === Step 7: 创建函数：将行业z-score映射到股票 ===\n",
        "def map_zscore_to_stocks(zscore_df):\n",
        "    result = {}\n",
        "    for date, row in zscore_df.iterrows():\n",
        "        mapped = {\n",
        "            stock: row[sector_etfs[stock_sector_map[stock]]]\n",
        "            for stock in stock_sector_map\n",
        "        }\n",
        "        result[date] = mapped\n",
        "    return pd.DataFrame(result).T.sort_index()\n",
        "\n",
        "# === Step 8: 映射成股票层面的情绪时间序列 ===\n",
        "sentiment_daily = map_zscore_to_stocks(zscore_daily)\n",
        "sentiment_weekly = map_zscore_to_stocks(zscore_weekly)\n",
        "sentiment_monthly = map_zscore_to_stocks(zscore_monthly)\n",
        "\n",
        "# === Step 9: 每一行进行 Min-Max 归一化（0~1）\n",
        "def min_max_scale(df):\n",
        "    return (df.T - df.min(axis=1)) / (df.max(axis=1) - df.min(axis=1) + 1e-8)  # 防除零\n",
        "sentiment_daily = min_max_scale(sentiment_daily).T\n",
        "sentiment_weekly = min_max_scale(sentiment_weekly).T\n",
        "sentiment_monthly = min_max_scale(sentiment_monthly).T\n",
        "\n",
        "# === Step 10: 保存 CSV（可选）\n",
        "sentiment_daily.to_csv(\"sector_sentiment_daily_scaled.csv\")\n",
        "sentiment_weekly.to_csv(\"sector_sentiment_weekly_scaled.csv\")\n",
        "sentiment_monthly.to_csv(\"sector_sentiment_monthly_scaled.csv\")\n",
        "\n",
        "# === Step 11: 预览结果 ===\n",
        "print(\"股票行业情绪 Min-Max 归一化 z-score 示例（每日）:\")\n",
        "print(sentiment_daily.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHJJ7HH7drq6",
        "outputId": "37862b21-1f3e-4c04-d82d-3f241ea23357"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  11 of 11 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票行业情绪 Min-Max 归一化 z-score 示例（每日）:\n",
            "                AAPL      MSFT      NVDA  JNJ  PFE  UNH       JPM       BAC  \\\n",
            "2020-02-03  0.753416  0.753416  0.753416  1.0  1.0  1.0  0.769407  0.769407   \n",
            "2020-02-04  0.720105  0.720105  0.720105  1.0  1.0  1.0  0.626125  0.626125   \n",
            "2020-02-05  0.612876  0.612876  0.612876  1.0  1.0  1.0  0.646808  0.646808   \n",
            "2020-02-06  0.617027  0.617027  0.617027  1.0  1.0  1.0  0.635209  0.635209   \n",
            "2020-02-07  0.630908  0.630908  0.630908  1.0  1.0  1.0  0.614805  0.614805   \n",
            "\n",
            "                 WFC       XOM  ...       DIS       UNP       HON       RTX  \\\n",
            "2020-02-03  0.769407  0.377857  ...  0.503079  0.798000  0.798000  0.798000   \n",
            "2020-02-04  0.626125  0.253226  ...  0.377655  0.810091  0.810091  0.810091   \n",
            "2020-02-05  0.646808  0.522986  ...  0.249631  0.779470  0.779470  0.779470   \n",
            "2020-02-06  0.635209  0.527689  ...  0.309166  0.781298  0.781298  0.781298   \n",
            "2020-02-07  0.614805  0.491884  ...  0.280278  0.783123  0.783123  0.783123   \n",
            "\n",
            "                 SHW       LIN       FCX       AMT       PLD      EQIX  \n",
            "2020-02-03  0.987491  0.987491  0.987491  0.437803  0.437803  0.437803  \n",
            "2020-02-04  0.872825  0.872825  0.872825  0.340260  0.340260  0.340260  \n",
            "2020-02-05  0.834052  0.834052  0.834052  0.287319  0.287319  0.287319  \n",
            "2020-02-06  0.836093  0.836093  0.836093  0.217518  0.217518  0.217518  \n",
            "2020-02-07  0.886111  0.886111  0.886111  0.202455  0.202455  0.202455  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 2: CVaR 函数 ===\n",
        "def compute_cvar_series(returns_df, weights, window=21, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Compute rolling portfolio CVaR using a fixed lookback window.\n",
        "    - returns_df: pd.DataFrame (daily asset returns)\n",
        "    - weights: np.array (portfolio weights)\n",
        "    - window: lookback window (default 21 days)\n",
        "    - alpha: tail quantile (default 5%)\n",
        "    \"\"\"\n",
        "    port_returns = returns_df @ weights\n",
        "    cvar_series = port_returns.rolling(window=window).apply(\n",
        "        lambda x: -np.mean(x[x < np.quantile(x, alpha)]) if len(x[x < np.quantile(x, alpha)]) > 0 else np.nan,\n",
        "        raw=False\n",
        "    )\n",
        "    return cvar_series.dropna()\n",
        "\n",
        "# === Step 3: 设置等权重 ===\n",
        "n_assets = returns.shape[1]\n",
        "equal_weights = np.ones(n_assets) / n_assets\n",
        "\n",
        "# === Step 4: 计算每日 CVaR（21日窗口）===\n",
        "cvar_daily = compute_cvar_series(returns, equal_weights, window=21, alpha=0.05)\n",
        "\n",
        "# === Step 5: 筛选每周/每月 ===\n",
        "cvar_weekly = cvar_daily[cvar_daily.index.weekday == 0]     # 每周一\n",
        "cvar_monthly = cvar_daily[cvar_daily.index.day == 1]        # 每月第一天\n",
        "\n",
        "# === Step 6: 合并成 DataFrame 并保存（可视化用）===\n",
        "cvar_df = pd.DataFrame({\n",
        "    \"CVaR_Daily\": cvar_daily,\n",
        "    \"CVaR_Weekly\": cvar_weekly,\n",
        "    \"CVaR_Monthly\": cvar_monthly\n",
        "})\n",
        "# 保存到 CSV 文件\n",
        "cvar_df.to_csv(\"cvar_frequencies.csv\")\n",
        "\n",
        "# 可选：预览\n",
        "print(\"CVaR 文件已保存: cvar_frequencies.csv\")\n",
        "print(cvar_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPH-ay2RjPsF",
        "outputId": "9fbec876-e4b5-416e-e9c0-e4cf66d4d0a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CVaR 文件已保存: cvar_frequencies.csv\n",
            "            CVaR_Daily  CVaR_Weekly  CVaR_Monthly\n",
            "Date                                             \n",
            "2020-02-03    0.020745     0.020745           NaN\n",
            "2020-02-04    0.020745          NaN           NaN\n",
            "2020-02-05    0.020745          NaN           NaN\n",
            "2020-02-06    0.020745          NaN           NaN\n",
            "2020-02-07    0.020745          NaN           NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hmmlearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMo6o2S7xz6x",
        "outputId": "5a92f870-64ae-4fcf-efcc-d9abe3bbfb75"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
            "Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/165.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m163.8/165.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Step 1: 下载市场代表性资产（S&P500） ===\n",
        "sp500 = yf.download(\"^GSPC\", start=\"2020-01-01\", end=\"2024-12-31\", auto_adjust=True)['Close']\n",
        "sp500_returns = sp500.pct_change().dropna().values.reshape(-1, 1)\n",
        "\n",
        "# === Step 2: 拟合 HMM 模型 ===\n",
        "model = GaussianHMM(n_components=3, covariance_type=\"full\", random_state=42)\n",
        "model.fit(sp500_returns)\n",
        "\n",
        "# === Step 3: 获取每天的状态概率（低/中/高波动）\n",
        "state_probs = model.predict_proba(sp500_returns)\n",
        "state_preds = model.predict(sp500_returns)\n",
        "\n",
        "# === Step 4: 输出为 DataFrame\n",
        "dates = sp500.index[1:]  # drop first nan\n",
        "hmm_df = pd.DataFrame(state_probs, columns=[\"Low_Vol\", \"Med_Vol\", \"High_Vol\"], index=dates)\n",
        "hmm_df[\"Regime_Label\"] = state_preds\n",
        "\n",
        "# === Step 5: 提取频率样本\n",
        "hmm_daily = hmm_df.copy()\n",
        "hmm_weekly = hmm_df[hmm_df.index.weekday == 0]\n",
        "hmm_monthly = hmm_df[hmm_df.index.day == 1]\n",
        "\n",
        "# === Step 6: 保存 & 显示示例\n",
        "hmm_daily.to_csv(\"hmm_states_daily.csv\")\n",
        "hmm_weekly.to_csv(\"hmm_states_weekly.csv\")\n",
        "hmm_monthly.to_csv(\"hmm_states_monthly.csv\")\n",
        "\n",
        "print(\"HMM 市场状态（每日前5行）:\")\n",
        "print(hmm_daily.head())\n",
        "\n",
        "# 可视化（可选）\n",
        "# hmm_daily[[\"Low_Vol\", \"Med_Vol\", \"High_Vol\"]].plot(figsize=(12,4), title=\"HMM Volatility Regime Probabilities\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BR5PxdHkXD7",
        "outputId": "550edfa6-4014-4e4b-8cba-fb7d64f690ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMM 市场状态（每日前5行）:\n",
            "             Low_Vol   Med_Vol      High_Vol  Regime_Label\n",
            "Date                                                      \n",
            "2020-01-03  0.988551  0.011449  6.812180e-15             0\n",
            "2020-01-06  0.011849  0.988142  8.988288e-06             1\n",
            "2020-01-07  0.984131  0.015557  3.116907e-04             0\n",
            "2020-01-08  0.015986  0.983896  1.173631e-04             1\n",
            "2020-01-09  0.980068  0.019585  3.468418e-04             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h6KMz7FQ5HqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "\n",
        "# === DCP 失败计数器 ===\n",
        "dcp_failed_count = {\"D\": 0, \"W\": 0, \"M\": 0}\n",
        "\n",
        "# === 多因子 Markowitz 优化器 ===\n",
        "def markowitz_multifactor(mu, cov, w_prev, sentiment_vec, hmm_vec, cvar_scalar,\n",
        "                          gamma_hold=0.01, gamma_trade=0.01,\n",
        "                          lambda_var=1.0, lambda_sent=10.0, lambda_hmm=5.0,\n",
        "                          verbose=False, freq=\"D\"):\n",
        "    global dcp_failed_count\n",
        "\n",
        "    n_assets = len(mu)\n",
        "    w = cp.Variable(n_assets)\n",
        "    z = w - w_prev\n",
        "\n",
        "    expected_return = mu @ w\n",
        "    holding_cost = cp.norm1(cp.pos(-w))\n",
        "    trading_cost = cp.norm1(z) + cp.sum_squares(z)\n",
        "    gamma_trade_eff = gamma_trade * (1 + hmm_vec[2])\n",
        "\n",
        "    sentiment_penalty = cp.sum(cp.multiply(sentiment_vec, cp.square(w)))\n",
        "    hmm_penalty = lambda_hmm * cp.sum_squares(w)\n",
        "    variance_penalty = cp.quad_form(w, cp.psd_wrap(cov))\n",
        "\n",
        "    objective = cp.Maximize(\n",
        "        expected_return\n",
        "        - gamma_hold * holding_cost\n",
        "        - gamma_trade_eff * trading_cost\n",
        "        - lambda_var * variance_penalty\n",
        "        - lambda_sent * sentiment_penalty\n",
        "        - hmm_penalty\n",
        "    )\n",
        "\n",
        "    constraints = [\n",
        "        cp.sum(w) == 1,\n",
        "        w >= 0,\n",
        "        w <= 1\n",
        "    ]\n",
        "\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "\n",
        "    if not problem.is_dcp():\n",
        "        dcp_failed_count[freq] += 1\n",
        "        if verbose:\n",
        "            print(\"DCP check failed.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        problem.solve()\n",
        "        if w.value is None:\n",
        "            if verbose:\n",
        "                print(\"Solver failed. Returning previous weights.\")\n",
        "            return None\n",
        "        return w.value\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Optimization error: {e}\")\n",
        "        return None\n",
        "\n",
        "# === 回测模拟函数 ===\n",
        "def simulate_portfolio(returns, sentiment, hmm, cvar, rebalance_freq='M', lookback=60):\n",
        "    returns = returns.dropna(axis=1)\n",
        "    sentiment = sentiment[returns.columns]\n",
        "    dates = returns.index\n",
        "    n_assets = returns.shape[1]\n",
        "    w_prev = np.ones(n_assets) / n_assets\n",
        "    port_returns = []\n",
        "\n",
        "    for i in range(lookback, len(returns)):\n",
        "        date = dates[i]\n",
        "        if rebalance_freq == 'M' and date.day != 1:\n",
        "            port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "            continue\n",
        "        if rebalance_freq == 'W' and date.weekday() != 0:\n",
        "            port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "            continue\n",
        "\n",
        "        window = returns.iloc[i - lookback:i]\n",
        "        mu = window.mean().values * 252\n",
        "        cov = window.cov().values * 252\n",
        "        try:\n",
        "            sentiment_vec = sentiment.loc[date].values\n",
        "            hmm_vec = hmm.loc[date][[\"Low_Vol\", \"Med_Vol\", \"High_Vol\"]].values\n",
        "            cvar_scalar = cvar.loc[date]\n",
        "        except:\n",
        "            port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            w_opt = markowitz_multifactor(mu, cov, w_prev, sentiment_vec, hmm_vec,\n",
        "                                          cvar_scalar, verbose=True, freq=rebalance_freq)\n",
        "            if w_opt is not None:\n",
        "                w_prev = w_opt\n",
        "        except Exception as e:\n",
        "            print(f\"Optimization failed on {date.date()}: {e}\")\n",
        "\n",
        "        port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "\n",
        "    return pd.Series(port_returns, index=returns.index[lookback:])\n",
        "\n",
        "# === 年化收益、波动率、Sharpe Ratio ===\n",
        "def performance_metrics(r, risk_free_rate=0.02):\n",
        "    ann_return = (1 + r.mean())**252 - 1\n",
        "    ann_vol = r.std() * np.sqrt(252)\n",
        "    sharpe_ratio = (ann_return) / ann_vol\n",
        "    return ann_return, ann_vol, sharpe_ratio\n",
        "\n",
        "# === 加载数据 ===\n",
        "returns = pd.read_csv(\"sector_portfolio_returns.csv\", index_col=0, parse_dates=True)\n",
        "sentiment_daily = pd.read_csv(\"sector_sentiment_daily_scaled.csv\", index_col=0, parse_dates=True)\n",
        "sentiment_weekly = pd.read_csv(\"sector_sentiment_weekly_scaled.csv\", index_col=0, parse_dates=True)\n",
        "sentiment_monthly = pd.read_csv(\"sector_sentiment_monthly_scaled.csv\", index_col=0, parse_dates=True)\n",
        "hmm_daily = pd.read_csv(\"hmm_states_daily.csv\", index_col=0, parse_dates=True)\n",
        "hmm_weekly = pd.read_csv(\"hmm_states_weekly.csv\", index_col=0, parse_dates=True)\n",
        "hmm_monthly = pd.read_csv(\"hmm_states_monthly.csv\", index_col=0, parse_dates=True)\n",
        "cvar = pd.read_csv(\"cvar_frequencies.csv\", index_col=0, parse_dates=True)\n",
        "\n",
        "# === 回测（D/W/M）\n",
        "for freq, sentiment, hmm in zip(['D', 'W', 'M'],\n",
        "                                [sentiment_daily, sentiment_weekly, sentiment_monthly],\n",
        "                                [hmm_daily, hmm_weekly, hmm_monthly]):\n",
        "    print(f\"\\n====== {freq}-rebalancing 回测开始 ======\")\n",
        "    cvar_col = f\"CVaR_{'Daily' if freq == 'D' else 'Weekly' if freq == 'W' else 'Monthly'}\"\n",
        "    r = simulate_portfolio(\n",
        "        returns,\n",
        "        sentiment,\n",
        "        hmm,\n",
        "        cvar[cvar_col],\n",
        "        rebalance_freq=freq,\n",
        "        lookback=60\n",
        "    )\n",
        "    ann_return, ann_vol, sharpe = performance_metrics(r)\n",
        "    print(f\"多因子 MVO 表现 ({freq}-rebalancing):\")\n",
        "    print(f\"Annual Return: {ann_return:.4f}\")\n",
        "    print(f\"Annual Volatility: {ann_vol:.4f}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
        "    print(f\"Total DCP check failed: {dcp_failed_count[freq]}\")\n"
      ],
      "metadata": {
        "id": "5Opa8yK1m1pB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0be517-eb47-4e3a-92ca-8318cc476047"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== D-rebalancing 回测开始 ======\n",
            "多因子 MVO 表现 (D-rebalancing):\n",
            "Annual Return: 0.2658\n",
            "Annual Volatility: 0.1681\n",
            "Sharpe Ratio: 1.5816\n",
            "Total DCP check failed: 0\n",
            "\n",
            "====== W-rebalancing 回测开始 ======\n",
            "多因子 MVO 表现 (W-rebalancing):\n",
            "Annual Return: 0.2680\n",
            "Annual Volatility: 0.1749\n",
            "Sharpe Ratio: 1.5327\n",
            "Total DCP check failed: 0\n",
            "\n",
            "====== M-rebalancing 回测开始 ======\n",
            "多因子 MVO 表现 (M-rebalancing):\n",
            "Annual Return: 0.3127\n",
            "Annual Volatility: 0.1749\n",
            "Sharpe Ratio: 1.7878\n",
            "Total DCP check failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0YAvnUNnr1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}