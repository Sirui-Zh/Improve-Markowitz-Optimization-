{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# é€‰å–æ¯ä¸ªindustry top3çš„è‚¡ç¥¨æ¥å»ºç«‹portfolio"
      ],
      "metadata": {
        "id": "cNqrQIpINvKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FMEj910Na0k",
        "outputId": "28b8cac2-3744-4d5a-96bc-a561c7956934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  33 of 33 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Daily returns calculated and saved.\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Top 3 stocks from each GICS sector\n",
        "tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"NVDA\",  # Technology\n",
        "    \"JNJ\", \"PFE\", \"UNH\",     # Healthcare\n",
        "    \"JPM\", \"BAC\", \"WFC\",     # Financials\n",
        "    \"XOM\", \"CVX\", \"COP\",     # Energy\n",
        "    \"PG\", \"KO\", \"PEP\",       # Consumer Staples\n",
        "    \"HD\", \"LOW\", \"TGT\",      # Consumer Discretionary\n",
        "    \"NEE\", \"DUK\", \"SO\",      # Utilities\n",
        "    \"GOOGL\", \"META\", \"DIS\",  # Communication Services\n",
        "    \"UNP\", \"HON\", \"RTX\",     # Industrials\n",
        "    \"SHW\", \"LIN\", \"FCX\",     # Materials\n",
        "    \"AMT\", \"PLD\", \"EQIX\"     # Real Estate\n",
        "]\n",
        "\n",
        "# Download full multi-indexed data\n",
        "data = yf.download(tickers, start=\"2020-01-01\", end=\"2024-12-31\", group_by='ticker', auto_adjust=True)\n",
        "\n",
        "# Extract \"Adj Close\" prices correctly for all tickers\n",
        "adj_close = pd.concat([data[ticker]['Close'] for ticker in tickers], axis=1)\n",
        "adj_close.columns = tickers\n",
        "\n",
        "# Calculate daily returns\n",
        "returns = adj_close.pct_change().dropna()\n",
        "\n",
        "# Save or display\n",
        "returns.to_csv(\"sector_portfolio_returns.csv\")\n",
        "print(\"âœ… Daily returns calculated and saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ç°åœ¨é¦–å…ˆè®¡ç®—ç­‰æƒé‡æŠ•èµ„ç»„åˆçš„å¹´å¹´å›æŠ¥ç‡å’Œå¹´æ³¢åŠ¨ç‡ï¼ˆholdä¸å˜ï¼Œä½œä¸ºbenchmarkï¼‰ï¼Œç„¶åä½¿ç”¨ä¼ ç»Ÿçš„mean varianceæ³•ï¼Œæ¯å¤©å’Œæ¯å‘¨ã€æ¯æœˆè°ƒæ•´æŠ•èµ„ç»„åˆï¼Œå¹¶è®¡ç®—è¯¥æŠ•èµ„ç»„åˆçš„å¹´å›æŠ¥ç‡ã€å¹´æ³¢åŠ¨ç‡ã€‚ç”¨ä½œbenchmark"
      ],
      "metadata": {
        "id": "BOMjwP92O9WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_stocks = returns.shape[1]\n",
        "equal_weights = np.ones(n_stocks) / n_stocks\n",
        "equal_portfolio_returns = returns.dot(equal_weights)\n",
        "\n",
        "annual_return = (1 + equal_portfolio_returns.mean()) ** 252 - 1\n",
        "annual_volatility = equal_portfolio_returns.std() * np.sqrt(252)\n",
        "risk_free_rate = 0.02\n",
        "sharpe_ratio = (annual_return - risk_free_rate) / annual_volatility\n",
        "\n",
        "print(f\"Equal-Weighted Portfolio\")\n",
        "print(f\"Annual Return: {annual_return:.4f}\")\n",
        "print(f\"Annual Volatility: {annual_volatility:.4f}\")\n",
        "print(f\"Sharpe Ratio (Rf=2%): {sharpe_ratio:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmhXix56OU04",
        "outputId": "54d9360f-47dc-41c8-caa6-89b5979fe435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ˆ Equal-Weighted Portfolio\n",
            "Annual Return: 0.1841\n",
            "Annual Volatility: 0.2134\n",
            "Sharpe Ratio (Rf=2%): 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "\n",
        "# === Load return data ===\n",
        "returns = pd.read_csv(\"sector_portfolio_returns.csv\", index_col=0, parse_dates=True)\n",
        "returns = returns.dropna(axis=1)\n",
        "\n",
        "# === Define Parameters and Data class ===\n",
        "class Parameters:\n",
        "    def __init__(self, n_assets):\n",
        "        self.w_min = np.zeros(n_assets)\n",
        "        self.w_max = np.ones(n_assets)\n",
        "        self.c_min = -0.1\n",
        "        self.c_max = 0.1\n",
        "        self.L_tar = 1.0\n",
        "        self.T_tar = 0.2\n",
        "        self.z_min = -0.2 * np.ones(n_assets)\n",
        "        self.z_max = 0.2 * np.ones(n_assets)\n",
        "        self.gamma_hold = 0.01\n",
        "        self.gamma_trade = 0.01\n",
        "        self.risk_target = 0.04\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, mean, cov, w_prev, kappa_short, kappa_borrow, kappa_spread, kappa_impact):\n",
        "        self.mean = mean\n",
        "        self.cov = cov\n",
        "        self.w_prev = w_prev\n",
        "        self.kappa_short = kappa_short\n",
        "        self.kappa_borrow = kappa_borrow\n",
        "        self.kappa_spread = kappa_spread\n",
        "        self.kappa_impact = kappa_impact\n",
        "\n",
        "# === DCP Failure Counter ===\n",
        "dcp_fail_count = 0\n",
        "\n",
        "# === Markowitz Optimizer ===\n",
        "def markowitz(data: Data, param: Parameters, verbose=False):\n",
        "    global dcp_fail_count\n",
        "    n_assets = param.w_min.shape[0]\n",
        "    w, c = cp.Variable(n_assets), cp.Variable()\n",
        "    z = w - data.w_prev\n",
        "    T = cp.norm1(z) / 2\n",
        "    L = cp.norm1(w)\n",
        "\n",
        "    risk = cp.quad_form(w, data.cov)\n",
        "    ret = w.T @ data.mean\n",
        "\n",
        "    holding_cost = data.kappa_short @ cp.pos(-w) + data.kappa_borrow * cp.pos(-c)\n",
        "    trading_cost = data.kappa_spread @ cp.abs(z) + data.kappa_impact @ cp.power(cp.abs(z), 3 / 2)\n",
        "\n",
        "    objective = ret - param.gamma_hold * holding_cost - param.gamma_trade * trading_cost\n",
        "\n",
        "    constraints = [\n",
        "        cp.sum(w) + c == 1,\n",
        "        param.w_min <= w,\n",
        "        w <= param.w_max,\n",
        "        L <= param.L_tar,\n",
        "        param.c_min <= c,\n",
        "        c <= param.c_max,\n",
        "        param.z_min <= z,\n",
        "        z <= param.z_max,\n",
        "        T <= param.T_tar,\n",
        "        risk <= param.risk_target\n",
        "    ]\n",
        "\n",
        "    problem = cp.Problem(cp.Maximize(objective), constraints)\n",
        "\n",
        "    if not problem.is_dcp():\n",
        "        dcp_fail_count += 1\n",
        "        if verbose:\n",
        "            print(\"DCP check failed.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        problem.solve()\n",
        "        return w.value\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Solver error: {e}\")\n",
        "        return None\n",
        "\n",
        "# === Rebalancing Simulation ===\n",
        "def simulate_markowitz_rebalancing(returns, rebalance_freq='M', lookback=60):\n",
        "    returns = returns.dropna(axis=1)\n",
        "    dates = returns.index\n",
        "    n_assets = returns.shape[1]\n",
        "\n",
        "    w_prev = np.ones(n_assets) / n_assets\n",
        "    portfolio_returns = []\n",
        "\n",
        "    kappa_short = 0.001 * np.ones(n_assets)\n",
        "    kappa_borrow = 0.001\n",
        "    kappa_spread = 0.005 * np.ones(n_assets)\n",
        "    kappa_impact = 0.01 * np.ones(n_assets)\n",
        "    param = Parameters(n_assets)\n",
        "\n",
        "    for i in range(lookback, len(returns)):\n",
        "        date = dates[i]\n",
        "        rebalance = (\n",
        "            rebalance_freq == 'D' or\n",
        "            (rebalance_freq == 'W' and date.weekday() == 0) or\n",
        "            (rebalance_freq == 'M' and date.day == 1)\n",
        "        )\n",
        "\n",
        "        if rebalance:\n",
        "            window = returns.iloc[i - lookback:i]\n",
        "            mu = window.mean().values * 252\n",
        "            cov = window.cov().values * 252\n",
        "            data = Data(mu, cov, w_prev, kappa_short, kappa_borrow, kappa_spread, kappa_impact)\n",
        "            w_opt = markowitz(data, param)\n",
        "            if w_opt is not None:\n",
        "                w_prev = w_opt\n",
        "\n",
        "        daily_return = returns.iloc[i].values @ w_prev\n",
        "        portfolio_returns.append(daily_return)\n",
        "\n",
        "    return pd.Series(portfolio_returns, index=returns.index[lookback:])\n",
        "\n",
        "# === Run simulations ===\n",
        "mvo_daily = simulate_markowitz_rebalancing(returns, 'D')\n",
        "mvo_weekly = simulate_markowitz_rebalancing(returns, 'W')\n",
        "mvo_monthly = simulate_markowitz_rebalancing(returns, 'M')\n",
        "\n",
        "# === Calculate annual metrics and Sharpe ratio ===\n",
        "def metrics_with_sharpe(r):\n",
        "    ann_return = (1 + r.mean()) ** 252 - 1\n",
        "    ann_vol = r.std() * np.sqrt(252)\n",
        "    sharpe = ann_return / ann_vol if ann_vol != 0 else np.nan\n",
        "    return ann_return, ann_vol, sharpe\n",
        "\n",
        "metrics = pd.DataFrame({\n",
        "    \"Strategy\": [\"MVO Daily\", \"MVO Weekly\", \"MVO Monthly\"],\n",
        "    \"Annual Return\": [metrics_with_sharpe(mvo_daily)[0],\n",
        "                      metrics_with_sharpe(mvo_weekly)[0],\n",
        "                      metrics_with_sharpe(mvo_monthly)[0]],\n",
        "    \"Annual Volatility\": [metrics_with_sharpe(mvo_daily)[1],\n",
        "                          metrics_with_sharpe(mvo_weekly)[1],\n",
        "                          metrics_with_sharpe(mvo_monthly)[1]],\n",
        "    \"Sharpe Ratio\": [metrics_with_sharpe(mvo_daily)[2],\n",
        "                     metrics_with_sharpe(mvo_weekly)[2],\n",
        "                     metrics_with_sharpe(mvo_monthly)[2]]\n",
        "})\n",
        "\n",
        "print(metrics)\n",
        "print(f\"Total DCP check failed: {dcp_fail_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViXU3-dbaLh0",
        "outputId": "df5ad574-185e-4f0b-e890-9efbfc5d47aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Strategy  Annual Return  Annual Volatility  Sharpe Ratio\n",
            "0    MVO Daily       0.235602           0.218313      1.079196\n",
            "1   MVO Weekly       0.182563           0.219035      0.833485\n",
            "2  MVO Monthly       0.390085           0.219573      1.776558\n",
            "âš ï¸ Total DCP check failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ç”¨æ–°çš„é£é™©æ§åˆ¶ä»£æ›¿varianceï¼Œè¿™é‡Œæˆ‘æ¢äº†VIX ç”¨industry sentimental indexè¯•è¯•ï¼Œå…¶ä»–çš„è¿˜æœ‰CVAR å’Œ HMM"
      ],
      "metadata": {
        "id": "aVLdi0Esda-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "\n",
        "# === Step 1: ETF å¯¹åº”è¡Œä¸š ===\n",
        "sector_etfs = {\n",
        "    \"Technology\": \"XLK\",\n",
        "    \"Healthcare\": \"XLV\",\n",
        "    \"Financials\": \"XLF\",\n",
        "    \"Energy\": \"XLE\",\n",
        "    \"Consumer Staples\": \"XLP\",\n",
        "    \"Consumer Discretionary\": \"XLY\",\n",
        "    \"Utilities\": \"XLU\",\n",
        "    \"Communication Services\": \"XLC\",\n",
        "    \"Industrials\": \"XLI\",\n",
        "    \"Materials\": \"XLB\",\n",
        "    \"Real Estate\": \"XLRE\"\n",
        "}\n",
        "\n",
        "# === Step 2: è‚¡ç¥¨ -> è¡Œä¸š æ˜ å°„ ===\n",
        "stock_sector_map = {\n",
        "    \"AAPL\": \"Technology\", \"MSFT\": \"Technology\", \"NVDA\": \"Technology\",\n",
        "    \"JNJ\": \"Healthcare\", \"PFE\": \"Healthcare\", \"UNH\": \"Healthcare\",\n",
        "    \"JPM\": \"Financials\", \"BAC\": \"Financials\", \"WFC\": \"Financials\",\n",
        "    \"XOM\": \"Energy\", \"CVX\": \"Energy\", \"COP\": \"Energy\",\n",
        "    \"PG\": \"Consumer Staples\", \"KO\": \"Consumer Staples\", \"PEP\": \"Consumer Staples\",\n",
        "    \"HD\": \"Consumer Discretionary\", \"LOW\": \"Consumer Discretionary\", \"TGT\": \"Consumer Discretionary\",\n",
        "    \"NEE\": \"Utilities\", \"DUK\": \"Utilities\", \"SO\": \"Utilities\",\n",
        "    \"GOOGL\": \"Communication Services\", \"META\": \"Communication Services\", \"DIS\": \"Communication Services\",\n",
        "    \"UNP\": \"Industrials\", \"HON\": \"Industrials\", \"RTX\": \"Industrials\",\n",
        "    \"SHW\": \"Materials\", \"LIN\": \"Materials\", \"FCX\": \"Materials\",\n",
        "    \"AMT\": \"Real Estate\", \"PLD\": \"Real Estate\", \"EQIX\": \"Real Estate\"\n",
        "}\n",
        "\n",
        "# === Step 3: ä¸‹è½½ ETF æ•°æ® ===\n",
        "etf_tickers = list(sector_etfs.values())\n",
        "etf_data = yf.download(etf_tickers, start=\"2020-01-01\", end=\"2024-12-31\", auto_adjust=True)\n",
        "etf_prices = etf_data['Close']\n",
        "etf_returns = etf_prices.pct_change().dropna()\n",
        "\n",
        "# === Step 4: æ»šåŠ¨å¹´åŒ–æ³¢åŠ¨ç‡ (21æ—¥çª—å£)\n",
        "vol_window = 21\n",
        "rolling_vol = etf_returns.rolling(window=vol_window).std() * np.sqrt(252)\n",
        "\n",
        "# === Step 5: è®¡ç®— rolling z-score ï¼ˆæ¯æ—¥ï¼‰\n",
        "zscore_daily = (rolling_vol - rolling_vol.mean()) / rolling_vol.std()\n",
        "zscore_daily = zscore_daily.dropna()\n",
        "\n",
        "# === Step 6: æå–æ¯å‘¨ï¼ˆå‘¨ä¸€ï¼‰ã€æ¯æœˆï¼ˆ1å·ï¼‰z-score\n",
        "zscore_weekly = zscore_daily[zscore_daily.index.weekday == 0]\n",
        "zscore_monthly = zscore_daily[zscore_daily.index.day == 1]\n",
        "\n",
        "# === Step 7: åˆ›å»ºå‡½æ•°ï¼šå°†è¡Œä¸šz-scoreæ˜ å°„åˆ°è‚¡ç¥¨ ===\n",
        "def map_zscore_to_stocks(zscore_df):\n",
        "    result = {}\n",
        "    for date, row in zscore_df.iterrows():\n",
        "        mapped = {\n",
        "            stock: row[sector_etfs[stock_sector_map[stock]]]\n",
        "            for stock in stock_sector_map\n",
        "        }\n",
        "        result[date] = mapped\n",
        "    return pd.DataFrame(result).T.sort_index()\n",
        "\n",
        "# === Step 8: æ˜ å°„æˆè‚¡ç¥¨å±‚é¢çš„æƒ…ç»ªæ—¶é—´åºåˆ— ===\n",
        "sentiment_daily = map_zscore_to_stocks(zscore_daily)\n",
        "sentiment_weekly = map_zscore_to_stocks(zscore_weekly)\n",
        "sentiment_monthly = map_zscore_to_stocks(zscore_monthly)\n",
        "\n",
        "# === Step 9: æ¯ä¸€è¡Œè¿›è¡Œ Min-Max å½’ä¸€åŒ–ï¼ˆ0~1ï¼‰\n",
        "def min_max_scale(df):\n",
        "    return (df.T - df.min(axis=1)) / (df.max(axis=1) - df.min(axis=1) + 1e-8)  # é˜²é™¤é›¶\n",
        "sentiment_daily = min_max_scale(sentiment_daily).T\n",
        "sentiment_weekly = min_max_scale(sentiment_weekly).T\n",
        "sentiment_monthly = min_max_scale(sentiment_monthly).T\n",
        "\n",
        "# === Step 10: ä¿å­˜ CSVï¼ˆå¯é€‰ï¼‰\n",
        "sentiment_daily.to_csv(\"sector_sentiment_daily_scaled.csv\")\n",
        "sentiment_weekly.to_csv(\"sector_sentiment_weekly_scaled.csv\")\n",
        "sentiment_monthly.to_csv(\"sector_sentiment_monthly_scaled.csv\")\n",
        "\n",
        "# === Step 11: é¢„è§ˆç»“æœ ===\n",
        "print(\"ğŸ“‰ è‚¡ç¥¨è¡Œä¸šæƒ…ç»ª Min-Max å½’ä¸€åŒ– z-score ç¤ºä¾‹ï¼ˆæ¯æ—¥ï¼‰:\")\n",
        "print(sentiment_daily.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHJJ7HH7drq6",
        "outputId": "4c22aed7-743b-4b05-fa6a-b5b336096028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  11 of 11 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‰ è‚¡ç¥¨è¡Œä¸šæƒ…ç»ª Min-Max å½’ä¸€åŒ– z-score ç¤ºä¾‹ï¼ˆæ¯æ—¥ï¼‰:\n",
            "                AAPL      MSFT      NVDA  JNJ  PFE  UNH       JPM       BAC  \\\n",
            "2020-02-03  0.753422  0.753422  0.753422  1.0  1.0  1.0  0.769424  0.769424   \n",
            "2020-02-04  0.720112  0.720112  0.720112  1.0  1.0  1.0  0.626141  0.626141   \n",
            "2020-02-05  0.612880  0.612880  0.612880  1.0  1.0  1.0  0.646822  0.646822   \n",
            "2020-02-06  0.617029  0.617029  0.617029  1.0  1.0  1.0  0.635222  0.635222   \n",
            "2020-02-07  0.630909  0.630909  0.630909  1.0  1.0  1.0  0.614819  0.614819   \n",
            "\n",
            "                 WFC       XOM  ...       DIS       UNP       HON       RTX  \\\n",
            "2020-02-03  0.769424  0.377860  ...  0.503074  0.798024  0.798024  0.798024   \n",
            "2020-02-04  0.626141  0.253231  ...  0.377652  0.810119  0.810119  0.810119   \n",
            "2020-02-05  0.646822  0.522988  ...  0.249627  0.779497  0.779497  0.779497   \n",
            "2020-02-06  0.635222  0.527691  ...  0.309162  0.781323  0.781323  0.781323   \n",
            "2020-02-07  0.614819  0.491887  ...  0.280273  0.783151  0.783151  0.783151   \n",
            "\n",
            "                 SHW       LIN       FCX       AMT       PLD      EQIX  \n",
            "2020-02-03  0.987499  0.987499  0.987499  0.437824  0.437824  0.437824  \n",
            "2020-02-04  0.872840  0.872840  0.872840  0.340280  0.340280  0.340280  \n",
            "2020-02-05  0.834062  0.834062  0.834062  0.287335  0.287335  0.287335  \n",
            "2020-02-06  0.836103  0.836103  0.836103  0.217538  0.217538  0.217538  \n",
            "2020-02-07  0.886124  0.886124  0.886124  0.202474  0.202474  0.202474  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 2: CVaR å‡½æ•° ===\n",
        "def compute_cvar_series(returns_df, weights, window=21, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Compute rolling portfolio CVaR using a fixed lookback window.\n",
        "    - returns_df: pd.DataFrame (daily asset returns)\n",
        "    - weights: np.array (portfolio weights)\n",
        "    - window: lookback window (default 21 days)\n",
        "    - alpha: tail quantile (default 5%)\n",
        "    \"\"\"\n",
        "    port_returns = returns_df @ weights\n",
        "    cvar_series = port_returns.rolling(window=window).apply(\n",
        "        lambda x: -np.mean(x[x < np.quantile(x, alpha)]) if len(x[x < np.quantile(x, alpha)]) > 0 else np.nan,\n",
        "        raw=False\n",
        "    )\n",
        "    return cvar_series.dropna()\n",
        "\n",
        "# === Step 3: è®¾ç½®ç­‰æƒé‡ ===\n",
        "n_assets = returns.shape[1]\n",
        "equal_weights = np.ones(n_assets) / n_assets\n",
        "\n",
        "# === Step 4: è®¡ç®—æ¯æ—¥ CVaRï¼ˆ21æ—¥çª—å£ï¼‰===\n",
        "cvar_daily = compute_cvar_series(returns, equal_weights, window=21, alpha=0.05)\n",
        "\n",
        "# === Step 5: ç­›é€‰æ¯å‘¨/æ¯æœˆ ===\n",
        "cvar_weekly = cvar_daily[cvar_daily.index.weekday == 0]     # æ¯å‘¨ä¸€\n",
        "cvar_monthly = cvar_daily[cvar_daily.index.day == 1]        # æ¯æœˆç¬¬ä¸€å¤©\n",
        "\n",
        "# === Step 6: åˆå¹¶æˆ DataFrame å¹¶ä¿å­˜ï¼ˆå¯è§†åŒ–ç”¨ï¼‰===\n",
        "cvar_df = pd.DataFrame({\n",
        "    \"CVaR_Daily\": cvar_daily,\n",
        "    \"CVaR_Weekly\": cvar_weekly,\n",
        "    \"CVaR_Monthly\": cvar_monthly\n",
        "})\n",
        "# ä¿å­˜åˆ° CSV æ–‡ä»¶\n",
        "cvar_df.to_csv(\"cvar_frequencies.csv\")\n",
        "\n",
        "# å¯é€‰ï¼šé¢„è§ˆ\n",
        "print(\"CVaR æ–‡ä»¶å·²ä¿å­˜: cvar_frequencies.csv\")\n",
        "print(cvar_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPH-ay2RjPsF",
        "outputId": "a068ec89-6460-49fd-aaf2-e10f99009fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CVaR æ–‡ä»¶å·²ä¿å­˜: cvar_frequencies.csv\n",
            "            CVaR_Daily  CVaR_Weekly  CVaR_Monthly\n",
            "Date                                             \n",
            "2020-02-03    0.020745     0.020745           NaN\n",
            "2020-02-04    0.020745          NaN           NaN\n",
            "2020-02-05    0.020745          NaN           NaN\n",
            "2020-02-06    0.020745          NaN           NaN\n",
            "2020-02-07    0.020745          NaN           NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hmmlearn.hmm import GaussianHMM\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Step 1: ä¸‹è½½å¸‚åœºä»£è¡¨æ€§èµ„äº§ï¼ˆS&P500ï¼‰ ===\n",
        "sp500 = yf.download(\"^GSPC\", start=\"2020-01-01\", end=\"2024-12-31\", auto_adjust=True)['Close']\n",
        "sp500_returns = sp500.pct_change().dropna().values.reshape(-1, 1)\n",
        "\n",
        "# === Step 2: æ‹Ÿåˆ HMM æ¨¡å‹ ===\n",
        "model = GaussianHMM(n_components=3, covariance_type=\"full\", random_state=42)\n",
        "model.fit(sp500_returns)\n",
        "\n",
        "# === Step 3: è·å–æ¯å¤©çš„çŠ¶æ€æ¦‚ç‡ï¼ˆä½/ä¸­/é«˜æ³¢åŠ¨ï¼‰\n",
        "state_probs = model.predict_proba(sp500_returns)\n",
        "state_preds = model.predict(sp500_returns)\n",
        "\n",
        "# === Step 4: è¾“å‡ºä¸º DataFrame\n",
        "dates = sp500.index[1:]  # drop first nan\n",
        "hmm_df = pd.DataFrame(state_probs, columns=[\"Low_Vol\", \"Med_Vol\", \"High_Vol\"], index=dates)\n",
        "hmm_df[\"Regime_Label\"] = state_preds\n",
        "\n",
        "# === Step 5: æå–é¢‘ç‡æ ·æœ¬\n",
        "hmm_daily = hmm_df.copy()\n",
        "hmm_weekly = hmm_df[hmm_df.index.weekday == 0]\n",
        "hmm_monthly = hmm_df[hmm_df.index.day == 1]\n",
        "\n",
        "# === Step 6: ä¿å­˜ & æ˜¾ç¤ºç¤ºä¾‹\n",
        "hmm_daily.to_csv(\"hmm_states_daily.csv\")\n",
        "hmm_weekly.to_csv(\"hmm_states_weekly.csv\")\n",
        "hmm_monthly.to_csv(\"hmm_states_monthly.csv\")\n",
        "\n",
        "print(\"HMM å¸‚åœºçŠ¶æ€ï¼ˆæ¯æ—¥å‰5è¡Œï¼‰:\")\n",
        "print(hmm_daily.head())\n",
        "\n",
        "# å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰\n",
        "# hmm_daily[[\"Low_Vol\", \"Med_Vol\", \"High_Vol\"]].plot(figsize=(12,4), title=\"HMM Volatility Regime Probabilities\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BR5PxdHkXD7",
        "outputId": "46764ae3-d0c6-48ef-e9eb-c27e48afbe91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š HMM å¸‚åœºçŠ¶æ€ï¼ˆæ¯æ—¥å‰5è¡Œï¼‰:\n",
            "             Low_Vol   Med_Vol      High_Vol  Regime_Label\n",
            "Date                                                      \n",
            "2020-01-03  0.988551  0.011449  6.812180e-15             0\n",
            "2020-01-06  0.011849  0.988142  8.988288e-06             1\n",
            "2020-01-07  0.984131  0.015557  3.116907e-04             0\n",
            "2020-01-08  0.015986  0.983896  1.173631e-04             1\n",
            "2020-01-09  0.980068  0.019585  3.468418e-04             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h6KMz7FQ5HqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "\n",
        "# === DCP å¤±è´¥è®¡æ•°å™¨ ===\n",
        "dcp_failed_count = {\"D\": 0, \"W\": 0, \"M\": 0}\n",
        "\n",
        "# === å¤šå› å­ Markowitz ä¼˜åŒ–å™¨ ===\n",
        "def markowitz_multifactor(mu, cov, w_prev, sentiment_vec, hmm_vec, cvar_scalar,\n",
        "                          gamma_hold=0.01, gamma_trade=0.01,\n",
        "                          lambda_var=1.0, lambda_sent=10.0, lambda_hmm=5.0,\n",
        "                          verbose=False, freq=\"D\"):\n",
        "    global dcp_failed_count\n",
        "\n",
        "    n_assets = len(mu)\n",
        "    w = cp.Variable(n_assets)\n",
        "    z = w - w_prev\n",
        "\n",
        "    expected_return = mu @ w\n",
        "    holding_cost = cp.norm1(cp.pos(-w))\n",
        "    trading_cost = cp.norm1(z) + cp.sum_squares(z)\n",
        "    gamma_trade_eff = gamma_trade * (1 + hmm_vec[2])\n",
        "\n",
        "    sentiment_penalty = cp.sum(cp.multiply(sentiment_vec, cp.square(w)))\n",
        "    hmm_penalty = lambda_hmm * cp.sum_squares(w)\n",
        "    variance_penalty = cp.quad_form(w, cp.psd_wrap(cov))\n",
        "\n",
        "    objective = cp.Maximize(\n",
        "        expected_return\n",
        "        - gamma_hold * holding_cost\n",
        "        - gamma_trade_eff * trading_cost\n",
        "        - lambda_var * variance_penalty\n",
        "        - lambda_sent * sentiment_penalty\n",
        "        - hmm_penalty\n",
        "    )\n",
        "\n",
        "    constraints = [\n",
        "        cp.sum(w) == 1,\n",
        "        w >= 0,\n",
        "        w <= 1\n",
        "    ]\n",
        "\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "\n",
        "    if not problem.is_dcp():\n",
        "        dcp_failed_count[freq] += 1\n",
        "        if verbose:\n",
        "            print(\"DCP check failed.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        problem.solve()\n",
        "        if w.value is None:\n",
        "            if verbose:\n",
        "                print(\"Solver failed. Returning previous weights.\")\n",
        "            return None\n",
        "        return w.value\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Optimization error: {e}\")\n",
        "        return None\n",
        "\n",
        "# === å›æµ‹æ¨¡æ‹Ÿå‡½æ•° ===\n",
        "def simulate_portfolio(returns, sentiment, hmm, cvar, rebalance_freq='M', lookback=60):\n",
        "    returns = returns.dropna(axis=1)\n",
        "    sentiment = sentiment[returns.columns]\n",
        "    dates = returns.index\n",
        "    n_assets = returns.shape[1]\n",
        "    w_prev = np.ones(n_assets) / n_assets\n",
        "    port_returns = []\n",
        "\n",
        "    for i in range(lookback, len(returns)):\n",
        "        date = dates[i]\n",
        "        if rebalance_freq == 'M' and date.day != 1:\n",
        "            port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "            continue\n",
        "        if rebalance_freq == 'W' and date.weekday() != 0:\n",
        "            port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "            continue\n",
        "\n",
        "        window = returns.iloc[i - lookback:i]\n",
        "        mu = window.mean().values * 252\n",
        "        cov = window.cov().values * 252\n",
        "        try:\n",
        "            sentiment_vec = sentiment.loc[date].values\n",
        "            hmm_vec = hmm.loc[date][[\"Low_Vol\", \"Med_Vol\", \"High_Vol\"]].values\n",
        "            cvar_scalar = cvar.loc[date]\n",
        "        except:\n",
        "            port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            w_opt = markowitz_multifactor(mu, cov, w_prev, sentiment_vec, hmm_vec,\n",
        "                                          cvar_scalar, verbose=True, freq=rebalance_freq)\n",
        "            if w_opt is not None:\n",
        "                w_prev = w_opt\n",
        "        except Exception as e:\n",
        "            print(f\"Optimization failed on {date.date()}: {e}\")\n",
        "\n",
        "        port_returns.append(returns.iloc[i].values @ w_prev)\n",
        "\n",
        "    return pd.Series(port_returns, index=returns.index[lookback:])\n",
        "\n",
        "# === å¹´åŒ–æ”¶ç›Šã€æ³¢åŠ¨ç‡ã€Sharpe Ratio ===\n",
        "def performance_metrics(r, risk_free_rate=0.02):\n",
        "    ann_return = (1 + r.mean())**252 - 1\n",
        "    ann_vol = r.std() * np.sqrt(252)\n",
        "    sharpe_ratio = (ann_return) / ann_vol\n",
        "    return ann_return, ann_vol, sharpe_ratio\n",
        "\n",
        "# === åŠ è½½æ•°æ® ===\n",
        "returns = pd.read_csv(\"sector_portfolio_returns.csv\", index_col=0, parse_dates=True)\n",
        "sentiment_daily = pd.read_csv(\"sector_sentiment_daily_scaled.csv\", index_col=0, parse_dates=True)\n",
        "sentiment_weekly = pd.read_csv(\"sector_sentiment_weekly_scaled.csv\", index_col=0, parse_dates=True)\n",
        "sentiment_monthly = pd.read_csv(\"sector_sentiment_monthly_scaled.csv\", index_col=0, parse_dates=True)\n",
        "hmm_daily = pd.read_csv(\"hmm_states_daily.csv\", index_col=0, parse_dates=True)\n",
        "hmm_weekly = pd.read_csv(\"hmm_states_weekly.csv\", index_col=0, parse_dates=True)\n",
        "hmm_monthly = pd.read_csv(\"hmm_states_monthly.csv\", index_col=0, parse_dates=True)\n",
        "cvar = pd.read_csv(\"cvar_frequencies.csv\", index_col=0, parse_dates=True)\n",
        "\n",
        "# === å›æµ‹ï¼ˆD/W/Mï¼‰\n",
        "for freq, sentiment, hmm in zip(['D', 'W', 'M'],\n",
        "                                [sentiment_daily, sentiment_weekly, sentiment_monthly],\n",
        "                                [hmm_daily, hmm_weekly, hmm_monthly]):\n",
        "    print(f\"\\n====== {freq}-rebalancing å›æµ‹å¼€å§‹ ======\")\n",
        "    cvar_col = f\"CVaR_{'Daily' if freq == 'D' else 'Weekly' if freq == 'W' else 'Monthly'}\"\n",
        "    r = simulate_portfolio(\n",
        "        returns,\n",
        "        sentiment,\n",
        "        hmm,\n",
        "        cvar[cvar_col],\n",
        "        rebalance_freq=freq,\n",
        "        lookback=60\n",
        "    )\n",
        "    ann_return, ann_vol, sharpe = performance_metrics(r)\n",
        "    print(f\"ğŸ“Š å¤šå› å­ MVO è¡¨ç° ({freq}-rebalancing):\")\n",
        "    print(f\"Annual Return: {ann_return:.4f}\")\n",
        "    print(f\"Annual Volatility: {ann_vol:.4f}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
        "    print(f\"Total DCP check failed: {dcp_failed_count[freq]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Opa8yK1m1pB",
        "outputId": "8d886f67-4d27-4f44-a6b4-0a98cc4a78b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== D-rebalancing å›æµ‹å¼€å§‹ ======\n",
            "ğŸ“Š å¤šå› å­ MVO è¡¨ç° (D-rebalancing):\n",
            "Annual Return: 0.2658\n",
            "Annual Volatility: 0.1681\n",
            "Sharpe Ratio: 1.5816\n",
            "âš ï¸ Total DCP check failed: 0\n",
            "\n",
            "====== W-rebalancing å›æµ‹å¼€å§‹ ======\n",
            "ğŸ“Š å¤šå› å­ MVO è¡¨ç° (W-rebalancing):\n",
            "Annual Return: 0.2680\n",
            "Annual Volatility: 0.1749\n",
            "Sharpe Ratio: 1.5327\n",
            "âš ï¸ Total DCP check failed: 0\n",
            "\n",
            "====== M-rebalancing å›æµ‹å¼€å§‹ ======\n",
            "ğŸ“Š å¤šå› å­ MVO è¡¨ç° (M-rebalancing):\n",
            "Annual Return: 0.3127\n",
            "Annual Volatility: 0.1749\n",
            "Sharpe Ratio: 1.7878\n",
            "âš ï¸ Total DCP check failed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0YAvnUNnr1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}